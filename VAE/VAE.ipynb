{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # tensorboardの出力先作成\n",
    "import matplotlib.pyplot as plt # 可視化\n",
    "import numpy as np # 計算\n",
    "import torch # 機械学習フレームワークとしてpytorchを使用\n",
    "import torch.nn as nn # クラス内で利用するモジュールのため簡略化\n",
    "import torch.nn.functional as F # クラス内で利用するモジュールのため簡略化\n",
    "from torch import optim # 最適化アルゴリズム\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorboardの利用\n",
    "from torchvision import datasets, transforms # データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboardのログの保存先\n",
    "if not os.path.exists(\"./logs\"):\n",
    "    os.makedirs(\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:03<00:00, 2.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.63MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNISTのデータをとってくるときに一次元化する前処理\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "# trainデータとtestデータに分けてデータセットを取得\n",
    "dataset_train_valid = datasets.MNIST(\"./\", train=True, download=True, transform=transform)\n",
    "dataset_test = datasets.MNIST(\"./\", train=False, download=True, transform=transform)\n",
    "\n",
    "# trainデータの20%はvalidationデータとして利用\n",
    "size_train_valid = len(dataset_train_valid) # 60000\n",
    "size_train = int(size_train_valid * 0.8) # 48000\n",
    "size_valid = size_train_valid - size_train # 12000\n",
    "dataset_train, dataset_valid = torch.utils.data.random_split(dataset_train_valid, [size_train, size_valid])\n",
    "\n",
    "# 取得したデータセットをDataLoader化する\n",
    "# バッチごとに取り出すことが目的\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1000, shuffle=True)\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=1000, shuffle=False)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        \"\"\"コンストラクタ\n",
    "\n",
    "        Args:\n",
    "            z_dim (int): 潜在空間の次元数\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "\n",
    "        Note:\n",
    "            eps (float): オーバーフローとアンダーフローを防ぐための微小量\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__() # VAEクラスはnn.Moduleを継承しているため親クラスのコンストラクタを呼ぶ必要がある\n",
    "        self.eps = np.spacing(1) # オーバーフローとアンダーフローを防ぐための微小量\n",
    "        self.x_dim = 28 * 28 # MNISTの場合は28×28の画像であるため\n",
    "        self.z_dim = z_dim # インスタンス化の際に潜在空間の次元数は自由に設定できる\n",
    "        self.enc_fc1 = nn.Linear(self.x_dim, 400) # エンコーダ1層目\n",
    "        self.enc_fc2 = nn.Linear(400, 200) # エンコーダ2層目\n",
    "        self.enc_fc3_mean = nn.Linear(200, z_dim) # 近似事後分布の平均\n",
    "        self.enc_fc3_logvar = nn.Linear(200, z_dim) # 近似事後分布の分散の対数\n",
    "        self.dec_fc1 = nn.Linear(z_dim, 200) # デコーダ1層目\n",
    "        self.dec_fc2 = nn.Linear(200, 400) # デコーダ2層目\n",
    "        self.dec_drop = nn.Dropout(p=0.2) # 過学習を防ぐために最終層の直前にドロップアウト\n",
    "        self.dec_fc3 = nn.Linear(400, self.x_dim) # デコーダ3層目\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        \"\"\"エンコーダ\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): (バッチサイズ, 入力次元数)サイズの入力データ\n",
    "\n",
    "        Returns:\n",
    "            mean (torch.tensor): 近似事後分布の平均\n",
    "            logvar (torch.tensor): 近似事後分布の分散の対数\n",
    "        \"\"\"\n",
    "        x = F.relu(self.enc_fc1(x))\n",
    "        x = F.relu(self.enc_fc2(x))\n",
    "        return self.enc_fc3_mean(x), self.enc_fc3_logvar(x)\n",
    "\n",
    "    def sample_z(self, mean, log_var, device):\n",
    "        \"\"\"Reparameterization trickに基づく潜在変数Zの疑似的なサンプリング\n",
    "\n",
    "        Args:\n",
    "            mean (torch.tensor): 近似事後分布の平均\n",
    "            logvar (torch.tensor): 近似事後分布の分散の対数\n",
    "            device (String): GPUが使える場合は\"cuda\"でそれ以外は\"cpu\"\n",
    "\n",
    "        Returns:\n",
    "            z (torch.tensor): (バッチサイズ, z_dim)サイズの潜在変数\n",
    "        \"\"\"\n",
    "        epsilon = torch.randn(mean.shape, device=device)\n",
    "\n",
    "        return mean + epsilon * torch.exp(0.5 * log_var)\n",
    "    def decoder(self, z):\n",
    "        \"\"\"デコーダ\n",
    "\n",
    "        Args:\n",
    "            z (torch.tensor): (バッチサイズ, z_dim)サイズの潜在変数\n",
    "\n",
    "        Returns:\n",
    "            y (torch.tensor): (バッチサイズ, 入力次元数)サイズの再構成データ\n",
    "        \"\"\"\n",
    "        z = F.relu(self.dec_fc1(z))\n",
    "        z = F.relu(self.dec_fc2(z))\n",
    "        z = self.dec_drop(z)\n",
    "        return torch.sigmoid(self.dec_fc3(z))\n",
    "\n",
    "    def forward(self, x, device):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): (バッチサイズ, 入力次元数)サイズの入力データ\n",
    "            device (String): GPUが使える場合は\"cuda\"でそれ以外は\"cpu\"\n",
    "\n",
    "        Returns:\n",
    "            KL (torch.float): KLダイバージェンス\n",
    "            reconstruction (torch.float): 再構成誤差\n",
    "            z (torch.tensor): (バッチサイズ, z_dim)サイズの潜在変数\n",
    "            y (torch.tensor): (バッチサイズ, 入力次元数)サイズの再構成データ            \n",
    "        \"\"\"\n",
    "        mean, log_var = self.encoder(x.to(device)) # encoder部分\n",
    "        z = self.sample_z(mean, log_var, device) # Reparameterization trick部分\n",
    "        y = self.decoder(z) # decoder部分\n",
    "        KL = 0.5 * torch.sum(1 + log_var - mean**2 - torch.exp(log_var)) # KLダイバージェンス計算\n",
    "        reconstruction = torch.sum(x * torch.log(y + self.eps) + (1 - x) * torch.log(1 - y + self.eps)) # 再構成誤差計算\n",
    "        return [KL, reconstruction], z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが使える場合はGPU上で動かす\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# VAEクラスのコンストラクタに潜在変数の次元数を渡す\n",
    "model = VAE(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今回はoptimizerとしてAdamを利用\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 最大更新回数は1000回\n",
    "num_epochs = 1000\n",
    "# 検証データのロスとその最小値を保持するための変数を十分大きな値で初期化しておく\n",
    "loss_valid = 10 ** 7\n",
    "loss_valid_min = 10 ** 7\n",
    "# early stoppingを判断するためのカウンタ変数\n",
    "num_no_improved = 0\n",
    "# tensorboardに記録するためのカウンタ変数\n",
    "num_batch_train = 0\n",
    "num_batch_valid = 0\n",
    "# tensorboardでモニタリングする\n",
    "writer = SummaryWriter(log_dir=\"./logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
