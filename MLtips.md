# Machine Learningのコツ

## One-Hotラベルを低次元に
情報圧縮の手法として述べられているのは「ランダム埋め込み」と呼ばれるアプローチで、特に「圧縮センシング（Compressed Sensing）」という理論に基づいています。この手法は、大きな特徴空間における情報を効率的に低次元に圧縮することを目的としています。以下に詳しく説明します。

### 1. One-Hot Encoding の問題
- One-hot encoding はカテゴリカルデータを数値化する手法で、各ユニークなカテゴリに対して一つの次元を割り当てます。
- 例えば、多数のユニークなエクササイズ（運動や練習問題）があるデータセットでは、One-hot encoding によって非常に多くの次元が必要になり、計算資源の効率が低下します。

### 2. ランダムベクトルの割り当て
- One-hot encoding の代わりに、各ユニークな入力タプル（例えば、学生とエクササイズの組み合わせ）に対してランダムベクトルを割り当てます。このベクトル \( \mathbf{n}_{q,a} \) はガウス分布（平均 0、分散 1 の独立正規分布）からサンプリングされ、次元は \( N \) とします。
- この方法では、ランダムベクトルが各入力に対して割り当てられるため、One-hot encoding のような巨大な次元を持つベクトルを生成せずにすみます。

### 3. 圧縮センシングの考え方
- 圧縮センシングとは、あるスパースな信号を元の次元よりもはるかに低い次元に圧縮しても、その信号を正確に復元できるという理論です。
- One-hot ベクトルは、1 つの要素だけが 1 で他はすべて 0 であるため「1 スパース信号」とみなせます。このようなスパースな信号は、ランダムな線形変換（つまりランダムベクトルによる圧縮）を通じて低次元に写像されても、正確に復元可能であるとされています。
- 圧縮センシングの理論によると、元の次元が \( d \) の信号を \( k \) 個のランダム線形射影に基づいて圧縮することで、元の信号を復元できる可能性があります。この理論を応用することで、One-hot ベクトルをランダムガウスベクトル（長さが \( \sim \log 2M \) ）に置き換えて情報を圧縮しています。

### 4. 効率的な低次元表現
- この方法によって、もともと高次元であった One-hot ベクトルをランダムな低次元ベクトルに置き換えることが可能となり、計算の効率が大幅に向上します。
- ランダムベクトルは各入力タプルに対して固定されるため、一貫性を保ちながら同じ情報を表現することが可能です。
- また、このアプローチは One-hot ベクトルに限らず、より複雑な学生のインタラクション（例えば、複数の特徴を含む）を表現する際にも拡張して使えるため、柔軟性が高いです。

### まとめ
- One-hot encoding の代わりにランダムガウスベクトルを用いることで、次元削減を行い、計算コストを削減できます。
- 圧縮センシングの理論に基づくこの手法により、スパースな信号である One-hot ベクトルを低次元に変換しつつ、その情報を失わずに保持することが可能となります。
- このアプローチは高次元の特徴空間の扱いを簡素化し、効率的な情報圧縮を実現します。

この手法は特に機械学習や深層学習において、高次元データの取り扱いを効率化するために有用です。

<br>

## ラベル平滑化
one-hot vectorを、「0」「1」と白黒はっきりさせないで、「少しボカした」数値にする。

<br>

## Memory-Augmented Neural Networks (MANN)
LSTMにインスパイヤされた？
Memory-Augmented Neural Networks (MANN)は、ニューラルネットワークに外部メモリを統合したアーキテクチャであり、特に少量のデータや短期の学習・適応が求められる問題に効果的です。通常のニューラルネットワークが持つ内部メモリとは異なり、MANNは拡張された外部メモリを利用して、過去の経験や知識を効率的に保持し、利用することができます。この外部メモリによって、ネットワークは過去の情報を取り出して処理することができるため、例えば少量のサンプルからの学習（few-shot learning）などにおいて大きな利点を発揮します。

代表的なMANNには以下のようなものがあります：

1. **Neural Turing Machine (NTM)**:
   - Neural Turing Machineは、外部メモリとそれを読み書きするための操作メカニズムを備えたアーキテクチャで、Turing Machine（チューリングマシン）をニューラルネットワークで実現しようとしたものです。NTMは、外部メモリに対する柔軟な読み書きが可能であり、系列データの学習や複雑なアルゴリズムを実行するために使われます。

2. **Differentiable Neural Computer (DNC)**:
   - Differentiable Neural ComputerはNTMの改良版であり、より効率的なメモリの読み書きと制御メカニズムを提供します。DNCは、より複雑な関係を学習し、問題に対する柔軟な解決策を見つけるために設計されています。

### 特徴と利点
- **外部メモリアクセス**: MANNは外部メモリを使用するため、従来のニューラルネットワークよりも大量のデータを効率的に保持できます。これは特に長期間にわたる情報の保持や一貫性のある行動を学習する場合に有利です。
- **少量データでの適応**: 少数の例から迅速に学習・適応する能力を持つため、few-shot learningやmeta-learningのようなタスクに強いです。過去の経験を外部メモリに保存し、それを利用して新しいタスクを効率的に学習します。
- **柔軟なデータ操作**: メモリへの読み書きが柔軟で、直感的な操作が可能であることから、アルゴリズム的な処理や系列データの変換など、複雑なタスクを学習できます。

### 応用分野
- **アルゴリズム学習**: MANNは、特にリストのソートやコピーなどのアルゴリズム的な問題を学習するのに適しており、従来のリカレントニューラルネットワーク（RNN）よりも複雑な関係性を扱うことが可能です。
- **少数ショット学習 (Few-shot Learning)**: MANNは新しいタスクに対して迅速に適応できるため、ラベル付きデータが少ない状況での学習に非常に適しています。
- **記憶力を必要とするタスク**: 会話システムやナビゲーションなど、複数ステップにわたって状態を維持することが必要なタスクにも利用されます。

MANNは通常のディープラーニングと比較して、より柔軟でメモリの有効活用が重要なタスクに対応するための強力なツールです。例えば、迅速な適応が必要な状況や、系列データを長期間にわたって保持し続ける必要がある状況での利用が考えられます。

<br>

## Sharpness-aware minimization (SAM)


### **1. SAMの背景**
- 通常、モデルのパラメータ $\omega$ を訓練損失 $L_{\text{train}}(\omega)$ を最小化することで学習します。しかし、単に訓練損失を最小化するだけでは、汎化性能（未知のデータに対する性能）が低い場合があります。
- SAMでは、訓練損失だけでなく、「**Sharpness（鋭さ）**」という概念を考慮して、損失関数を滑らかにし、汎化性能を高めるようにパラメータを更新します。

---

### **2. Sharpness（鋭さ）の定義**
- Sharpness \(s(\omega, \rho)\) は、以下のように定義されます：
  $$
  s(\omega, \rho) := \max_{\|\epsilon\|_2 \leq \rho} \big( L_{\text{train}}(\omega + \epsilon) - L_{\text{train}}(\omega) \big)
  $$
  - $\|\epsilon\|_2 \leq \rho$: パラメータ空間で $\epsilon$ を $\rho$ の範囲内に制限します。
  - $L_{\text{train}}(\omega + \epsilon)$: $\omega$ を少しだけ動かした時の訓練損失。
  - Sharpnessは、「パラメータ空間の近傍（半径 $\rho$ の範囲）で、損失がどれだけ変動するか」を測る尺度です。

---

### **3. SAMの損失関数**
- SAMは、Sharpnessを考慮して訓練損失を次のように再定義します：
  $$
  L^{\text{SAM}}_{\text{train}}(\omega) := \max_{\|\epsilon\|_2 \leq \rho} L_{\text{train}}(\omega + \epsilon)
  $$
  - **解釈**: $\omega$ の近傍で最悪の場合の訓練損失を最小化する、という方針。
  - 通常の訓練（$\rho = 0$）と異なり、パラメータの近傍で損失があまり急激に変化しない（なだらかになる）ように調整します。

---

### **4. 勾配更新の導出**
- この「$\max$」操作（近傍で最悪の損失を探す）は計算コストが高いため、Taylor展開を使って近似します。
  - まず、$\epsilon^*$ を次のように求めます：
    $$
    \epsilon^* = \arg\max_{\|\epsilon\|_2 \leq \rho} \epsilon^\top \nabla L_{\text{train}}(\omega)
    $$
  - この解は、次のように表されます：
    $$
    \epsilon^* = \rho \frac{\nabla L_{\text{train}}(\omega)}{\|\nabla L_{\text{train}}(\omega)\|}
    $$

- この近似結果を使うと、SAMによる勾配更新式は以下のようになります：
  $$
  \omega_{t+1} = \omega_t - \eta \nabla L_{\text{train}} \Big(\omega_t + \rho \frac{\nabla L_{\text{train}}(\omega_t)}{\|\nabla L_{\text{train}}(\omega_t)\|}\Big)
  $$
  - $\rho$: パラメータ空間での「近傍の大きさ」を制御するハイパーパラメータ。
  - この更新式では、$\omega$ の近傍での損失を考慮した上で、パラメータを更新します。

---

### **5. SAMの効果**
- **なだらかな損失地形の探索**: SAMは、損失地形が「幅広く浅い谷」を持つようにモデルを訓練します。これにより、汎化性能が向上します。
- **局所最適解の回避**: パラメータ近傍を考慮することで、シャープな局所最適解に陥るリスクを減らします。

---

### **6. まとめ**
SAMは、通常の最適化手法に比べて、損失地形の形状（鋭さ）を考慮する点が特徴です。このアプローチにより、訓練データだけでなく、未知のデータにも高い性能を発揮するモデルを構築できる可能性があります。




<br>

## 因子分析
因子分析が各観測変数から共通している部分を探索する分析であるのに対し、主成分分析は各観測変数をより少ない変数にまとめる分析です。  
複数の変数間の相関係数をまとめた相関行列から因子数を決定し、因子数を指定して因子分析を実行する。因子負荷量と共通性から因子に名前をつけて解釈性を持たせて理解する。  
[text](https://toukei-lab.com/factor-analysis)

<br>

## 時系列の問題
分布シフト Revin良さそう
けど、同じ形状で平均分散だけが違う系列が入ってきたら同じ予測をする？

<br>

## in-context learning
**In-Context Learning (ICL)** は、モデルが明示的なパラメータ更新を行わずに、入力コンテキスト（プロンプト）からタスクを学び、遂行する能力を指します。この概念は特に大規模言語モデル（LLMs）の進展に伴って注目されています。

---

### **In-Context Learning の特徴**
1. **プロンプトベースの学習**:
   - モデルにタスクを解くための例（プロンプト）を与えるだけで、タスクを実行できます。
   - 例えば、文法修正タスクの場合：
     ```
     Input: "She go to school."
     Output: "She goes to school."
     ```
     モデルにこのような入力-出力ペアを提示し、次の例に基づいてタスクを続行させる。

2. **パラメータ更新なし**:
   - モデルの内部パラメータを変更することなく、入力内の文脈から学習します。
   - 従来のトレーニングとは異なり、プロンプト内の情報を活用して即時的な適応を実現します。

3. **タスク多様性**:
   - 翻訳、要約、分類、生成など、さまざまなタスクをプロンプトの設計次第で処理できます。

---

### **仕組み**
In-Context Learning は主に以下のメカニズムを活用します：

1. **モデルの事前学習の一般化能力**:
   - 大規模なコーパスでの事前学習により、モデルは広範なパターンや構造を学習します。
   - これにより、プロンプト内の例から新しいタスクを即時に理解できるようになります。

2. **例からのパターン抽出**:
   - 入力内の例（コンテキスト）から、タスクの構造やルールを推測します。
   - モデルはプロンプト内の入力-出力関係を一般化し、類似の入力に対応する出力を生成します。

---

### **In-Context Learning の種類**
1. **Zero-Shot Learning**:
   - 明示的な例を与えず、タスクの説明だけで処理します。
     ```
     "Translate the following English sentence to French: 'Hello, how are you?'"
     ```
   
2. **Few-Shot Learning**:
   - プロンプト内にいくつかの例を提示し、それを基にタスクを実行します。
     ```
     English: "Good morning." → French: "Bonjour."
     English: "How are you?" → French: "Comment ça va?"
     Translate: "Thank you."
     ```

3. **Chain-of-Thought (CoT) Reasoning**:
   - タスク遂行において推論のステップを明示的に示すプロンプト設計。
     ```
     Question: If you have 3 apples and buy 2 more, how many apples do you have?
     Answer: Let's think step by step. Initially, there are 3 apples. If you buy 2 more, the total becomes 3 + 2 = 5. So, the answer is 5.
     ```

---

### **応用例**
1. **自然言語処理**:
   - 翻訳、要約、質問応答、文法修正など。
2. **計算・推論**:
   - 数学的な計算や因果推論。
3. **プログラミング支援**:
   - コード補完、デバッグ。

---

### **課題**
1. **スケーリングの限界**:
   - プロンプトの長さが制限されているため、非常に長い文脈を含むタスクでは性能が低下。
2. **依存性の不明確さ**:
   - モデルが正しい文脈から正しいパターンを抽出しているかの保証がない。
3. **不確実性**:
   - タスクに対する適応度がプロンプト設計に大きく依存する。

---

In-Context Learning はモデルの柔軟性を高め、事前トレーニングの汎用性を最大限に引き出す技術ですが、課題もあるため、適切な設計が重要です。

<br>
##

<br>
##

<br>
##

<br>
##

<br>

## 調べたいこと
reversible instance  normalization  
Kim, Taesung, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jangho Choi, and J. Choo. 2022. “Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift.” International Conference on Learning Representations.
